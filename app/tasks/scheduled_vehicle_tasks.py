"""
å®šæ—¶ä»»åŠ¡æ¨¡å— - åŸºäºCelery Beatå®ç°å‘¨æœŸæ€§ä»»åŠ¡
"""
from celery import current_task
from app.tasks.celery_app import celery_app
from app.core.logging import app_logger
from datetime import datetime, timedelta, timezone
from typing import Dict, List
import asyncio


@celery_app.task(bind=True, max_retries=3)
def scheduled_vehicle_update(self, channel_ids: List[int] = None, force_update: bool = False):
    """
    å®šæ—¶è½¦å‹æ•°æ®æ›´æ–°ä»»åŠ¡
    
    Args:
        channel_ids: è¦æ›´æ–°çš„æ¸ é“IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™æ›´æ–°æ‰€æœ‰æ¸ é“
        force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    """
    from app.core.database import AsyncSessionLocal
    from app.models.vehicle_update import ProcessingJob
    from app.services.vehicle_update_service import vehicle_update_service
    from app.schemas.vehicle_update import UpdateRequestSchema
    
    try:
        app_logger.info(f"â° å¼€å§‹æ‰§è¡Œå®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡: channels={channel_ids}, force_update={force_update}")
        current_task.update_state(
            state='PROGRESS',
            meta={
                'current': 0,
                'total': 100,
                'progress': 0,
                'status': 'æ­£åœ¨æ‰§è¡Œå®šæ—¶è½¦å‹æ›´æ–°...',
                'channel_ids': channel_ids,
                'force_update': force_update
            }
        )
        # è·å–æ‰€æœ‰æ¸ é“
        if not channel_ids:
            channels = asyncio.run(vehicle_update_service.get_supported_channels())
            channel_ids = [channel_id for channel_id in channels.supported_channels.keys()]
        total_channels = len(channel_ids)
        completed_channels = 0
        results = []
        for channel_id in channel_ids:
            # æ¯ä¸ªæ¸ é“éƒ½å†™å…¥ä¸€æ¡processing_jobs
            job_id = None
            try:
                # --- æ”¹ä¸ºåŒæ­¥å†™æ³• ---
                def create_job_sync():
                    from app.core.database import get_sync_session
                    from app.models.vehicle_update import ProcessingJob
                    with get_sync_session() as db:
                        processing_job = ProcessingJob(
                            job_type="scheduled_vehicle_update",
                            status="running",
                            parameters={
                                "channel_id": channel_id,
                                "force_update": force_update,
                                "celery_task_id": self.request.id
                            },
                            pipeline_version="1.0.0",
                            created_by_user_id_fk=None,
                            started_at=datetime.now(timezone.utc)
                        )
                        db.add(processing_job)
                        db.commit()
                        db.refresh(processing_job)
                        return processing_job.job_id
                job_id = create_job_sync()
                app_logger.info(f"ğŸ“ åˆ›å»ºå®šæ—¶ä»»åŠ¡è®°å½•: job_id={job_id}, channel_id={channel_id}")
                # æ‰§è¡Œæ›´æ–°
                update_request = UpdateRequestSchema(
                    channel_id=channel_id,
                    force_update=force_update,
                    filters={}
                )
                result = asyncio.run(vehicle_update_service.update_vehicles_direct(update_request))
                # --- æ”¹ä¸ºåŒæ­¥å†™æ³• ---
                def update_job_completed_sync():
                    from app.core.database import get_sync_session
                    from app.models.vehicle_update import ProcessingJob
                    with get_sync_session() as db:
                        job = db.get(ProcessingJob, job_id)
                        if job:
                            job.status = "completed"
                            job.completed_at = datetime.utcnow()
                            job.result_summary = f"å®šæ—¶è½¦å‹æ›´æ–°å®Œæˆ: æ–°å¢{result.new_vehicles}ä¸ª, æ›´æ–°{result.updated_vehicles}ä¸ª, æœªå˜{result.unchanged_vehicles}ä¸ª"
                            db.commit()
                            app_logger.info(f"ğŸ“ æ›´æ–°å®šæ—¶ä»»åŠ¡è®°å½•ä¸ºå®ŒæˆçŠ¶æ€: job_id={job_id}")
                update_job_completed_sync()
                channel_result = {
                    'channel_id': channel_id,
                    'channel_name': result.channel_name,
                    'total_crawled': result.total_crawled,
                    'new_vehicles': result.new_vehicles,
                    'updated_vehicles': result.updated_vehicles,
                    'unchanged_vehicles': result.unchanged_vehicles,
                    'status': 'success',
                    'job_id': job_id
                }
                results.append(channel_result)
                completed_channels += 1
                progress = int((completed_channels / total_channels) * 100)
                current_task.update_state(
                    state='PROGRESS',
                    meta={
                        'current': completed_channels,
                        'total': total_channels,
                        'progress': progress,
                        'status': f'å·²å®Œæˆ {completed_channels}/{total_channels} ä¸ªæ¸ é“',
                        'results': results
                    }
                )
                app_logger.info(f"âœ… æ¸ é“ {channel_id} æ›´æ–°å®Œæˆ: æ–°å¢{result.new_vehicles}ä¸ª, æ›´æ–°{result.updated_vehicles}ä¸ª")
            except Exception as e:
                app_logger.error(f"âŒ æ¸ é“ {channel_id} æ›´æ–°å¤±è´¥: {e}")
                # --- æ”¹ä¸ºåŒæ­¥å†™æ³• ---
                if job_id:
                    def update_job_failed_sync():
                        from app.core.database import get_sync_session
                        from app.models.vehicle_update import ProcessingJob
                        with get_sync_session() as db:
                            job = db.get(ProcessingJob, job_id)
                            if job:
                                job.status = "failed"
                                job.completed_at = datetime.utcnow()
                                job.result_summary = f"å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}"
                                db.commit()
                                app_logger.info(f"ğŸ“ æ›´æ–°å®šæ—¶ä»»åŠ¡è®°å½•ä¸ºå¤±è´¥çŠ¶æ€: job_id={job_id}")
                    update_job_failed_sync()
                channel_result = {
                    'channel_id': channel_id,
                    'channel_name': f'æ¸ é“{channel_id}',
                    'error': str(e),
                    'status': 'failed',
                    'job_id': job_id
                }
                results.append(channel_result)
                completed_channels += 1
        # æ±‡æ€»ç»Ÿè®¡
        total_new = sum(r.get('new_vehicles', 0) for r in results if r.get('status') == 'success')
        total_updated = sum(r.get('updated_vehicles', 0) for r in results if r.get('status') == 'success')
        success_count = len([r for r in results if r.get('status') == 'success'])
        failed_count = len([r for r in results if r.get('status') == 'failed'])
        app_logger.info(f"ğŸ‰ å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å®Œæˆ: æˆåŠŸ{success_count}ä¸ªæ¸ é“, å¤±è´¥{failed_count}ä¸ªæ¸ é“, æ€»è®¡æ–°å¢{total_new}ä¸ªè½¦å‹, æ›´æ–°{total_updated}ä¸ªè½¦å‹")
        return {
            'status': 'completed',
            'total_channels': total_channels,
            'success_count': success_count,
            'failed_count': failed_count,
            'total_new_vehicles': total_new,
            'total_updated_vehicles': total_updated,
            'results': results,
            'message': f'å®šæ—¶è½¦å‹æ›´æ–°å®Œæˆ: æˆåŠŸ{success_count}/{total_channels}ä¸ªæ¸ é“'
        }
    except Exception as exc:
        app_logger.error(f"âŒ å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {exc}")
        current_task.update_state(
            state='FAILURE',
            meta={
                'error': str(exc),
                'message': f'å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {exc}'
            }
        )
        raise exc





@celery_app.task
def health_check():
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥ä»»åŠ¡
    """
    try:
        app_logger.info("ğŸ¥ æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        
        # åˆ›å»ºprocessing_jobè®°å½•
        from app.core.database import AsyncSessionLocal
        from app.models.vehicle_update import ProcessingJob
        
        async def create_health_job_record():
            async with AsyncSessionLocal() as db:
                processing_job = ProcessingJob(
                    job_type="health_check",
                    status="running",
                    parameters={
                        "celery_task_id": health_check.request.id
                    },
                    pipeline_version="1.0.0",
                    created_by_user_id_fk=None,
                    started_at=datetime.utcnow()
                )
                db.add(processing_job)
                await db.flush()
                await db.commit()
                return processing_job
        
        processing_job = asyncio.run(create_health_job_record())
        app_logger.info(f"ğŸ“ åˆ›å»ºå¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•: job_id={processing_job.job_id}")
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        from app.core.database import sync_engine
        from sqlalchemy import text
        with sync_engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            db_status = "healthy" if result.fetchone() else "unhealthy"
        
        # æ£€æŸ¥Redisè¿æ¥
        from app.core.config import settings
        import redis
        try:
            r = redis.from_url(settings.REDIS_URL)
            r.ping()
            redis_status = "healthy"
        except:
            redis_status = "unhealthy"
        
        health_info = {
            'timestamp': datetime.now().isoformat(),
            'database': db_status,
            'redis': redis_status,
            'overall': "healthy" if db_status == "healthy" and redis_status == "healthy" else "unhealthy"
        }
        
        app_logger.info(f"âœ… å¥åº·æ£€æŸ¥å®Œæˆ: {health_info}")
        
        # æ›´æ–°processing_jobè®°å½•ä¸ºå®ŒæˆçŠ¶æ€
        async def update_health_job_completed():
            async with AsyncSessionLocal() as db:
                job = await db.get(ProcessingJob, processing_job.job_id)
                if job:
                    job.status = "completed"
                    job.completed_at = datetime.utcnow()
                    job.result_summary = f"å¥åº·æ£€æŸ¥å®Œæˆ: {health_info['overall']}"
                    await db.commit()
                    app_logger.info(f"ğŸ“ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•ä¸ºå®ŒæˆçŠ¶æ€: job_id={processing_job.job_id}")
        
        asyncio.run(update_health_job_completed())
        return health_info
        
    except Exception as e:
        app_logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        
        # æ›´æ–°processing_jobè®°å½•ä¸ºå¤±è´¥çŠ¶æ€
        try:
            async def update_health_job_failed():
                async with AsyncSessionLocal() as db:
                    job = await db.get(ProcessingJob, processing_job.job_id)
                    if job:
                        job.status = "failed"
                        job.completed_at = datetime.utcnow()
                        job.result_summary = f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}"
                        await db.commit()
                        app_logger.info(f"ğŸ“ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•ä¸ºå¤±è´¥çŠ¶æ€: job_id={processing_job.job_id}")
            
            asyncio.run(update_health_job_failed())
        except Exception as update_error:
            app_logger.error(f"âŒ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•å¤±è´¥: {update_error}")
        
        return {
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'overall': 'unhealthy'
        } 