"""
å®šæ—¶ä»»åŠ¡æ¨¡å— - åŸºäºCelery Beatå®ç°å‘¨æœŸæ€§ä»»åŠ¡ (åŒæ­¥ç‰ˆæœ¬)
"""
from celery import current_task
from app.tasks.celery_app import celery_app
from app.core.logging import app_logger
from datetime import datetime, timedelta, timezone
from typing import Dict, List


@celery_app.task(bind=True, max_retries=3)
def scheduled_vehicle_update(self, channel_ids: List[int] = None, force_update: bool = False):
    """
    å®šæ—¶è½¦å‹æ•°æ®æ›´æ–°ä»»åŠ¡ - åŒæ­¥ç‰ˆæœ¬
    
    Args:
        channel_ids: è¦æ›´æ–°çš„æ¸ é“IDåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™æ›´æ–°æ‰€æœ‰æ¸ é“
        force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
    """
    from app.core.database import get_sync_session
    from app.models.vehicle_update import ProcessingJob
    from app.services.vehicle_update_service_sync import vehicle_update_service_sync
    from app.schemas.vehicle_update import UpdateRequestSchema
    
    try:
        app_logger.info(f"â° å¼€å§‹æ‰§è¡Œå®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡: channels={channel_ids}, force_update={force_update}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¹åº”çš„ProcessingJobè®°å½•ï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
        celery_task_id = self.request.id
        
        current_task.update_state(
            state='PROGRESS',
            meta={
                'current': 0,
                'total': 100,
                'progress': 0,
                'status': 'æ­£åœ¨æ‰§è¡Œå®šæ—¶è½¦å‹æ›´æ–°...',
                'channel_ids': channel_ids,
                'force_update': force_update,
                'celery_task_id': celery_task_id
            }
        )
        
        # è·å–æ‰€æœ‰æ¸ é“ - ä½¿ç”¨åŒæ­¥æœåŠ¡
        if not channel_ids:
            channels = vehicle_update_service_sync.get_supported_channels()
            channel_ids = [channel_id for channel_id in channels.supported_channels.keys()]
        total_channels = len(channel_ids)
        completed_channels = 0
        results = []
        
        for channel_id in channel_ids:
            # æ¯ä¸ªæ¸ é“éƒ½å†™å…¥ä¸€æ¡processing_jobs
            job_id = None
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¯¹åº”çš„ProcessingJobè®°å½•
                with get_sync_session() as db:
                    # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰ç›¸åŒcelery_task_idå’Œchannel_idçš„è®°å½•
                    existing_job = db.query(ProcessingJob).filter(
                        ProcessingJob.job_type == "scheduled_vehicle_update",
                        ProcessingJob.parameters.contains({
                            "celery_task_id": celery_task_id,
                            "channel_id": channel_id
                        })
                    ).first()
                    
                    if existing_job:
                        # å¦‚æœæ‰¾åˆ°ç°æœ‰è®°å½•ï¼Œä½¿ç”¨å®ƒ
                        job_id = existing_job.job_id
                        app_logger.info(f"ğŸ”„ å‘ç°ç°æœ‰ä»»åŠ¡è®°å½•ï¼Œç»§ç»­æ‰§è¡Œ: job_id={job_id}, channel_id={channel_id}")
                        
                        # å¦‚æœçŠ¶æ€æ˜¯runningï¼Œè¯´æ˜ä»»åŠ¡è¢«ä¸­æ–­åé‡æ–°å¯åŠ¨
                        if existing_job.status == "running":
                            app_logger.info(f"ğŸ”„ ä»»åŠ¡è¢«ä¸­æ–­åé‡æ–°å¯åŠ¨ï¼Œç»§ç»­æ‰§è¡Œ: job_id={job_id}")
                    else:
                        # åˆ›å»ºæ–°çš„ä»»åŠ¡è®°å½•
                        processing_job = ProcessingJob(
                            job_type="scheduled_vehicle_update",
                            status="running",
                            parameters={
                                "channel_id": channel_id,
                                "force_update": force_update,
                                "celery_task_id": celery_task_id
                            },
                            pipeline_version="1.0.0",
                            created_by_user_id_fk=None,
                            started_at=datetime.now(timezone.utc)
                        )
                        db.add(processing_job)
                        db.commit()
                        db.refresh(processing_job)
                        job_id = processing_job.job_id
                        app_logger.info(f"ğŸ“ åˆ›å»ºæ–°çš„å®šæ—¶ä»»åŠ¡è®°å½•: job_id={job_id}, channel_id={channel_id}")
                
                # æ‰§è¡Œæ›´æ–° - ä½¿ç”¨åŒæ­¥æœåŠ¡
                update_request = UpdateRequestSchema(
                    channel_id=channel_id,
                    force_update=force_update,
                    filters={}
                )
                result = vehicle_update_service_sync.update_vehicles_direct(update_request)
                
                # æ›´æ–°ä»»åŠ¡è®°å½•ä¸ºå®ŒæˆçŠ¶æ€ - åŒæ­¥ç‰ˆæœ¬
                with get_sync_session() as db:
                    job = db.get(ProcessingJob, job_id)
                    if job:
                        job.status = "completed"
                        job.completed_at = datetime.utcnow()
                        job.result_summary = f"å®šæ—¶è½¦å‹æ›´æ–°å®Œæˆ: æ–°å¢{result.new_vehicles}ä¸ª, æ›´æ–°{result.updated_vehicles}ä¸ª, æœªå˜{result.unchanged_vehicles}ä¸ª"
                        db.commit()
                        app_logger.info(f"ğŸ“ æ›´æ–°å®šæ—¶ä»»åŠ¡è®°å½•ä¸ºå®ŒæˆçŠ¶æ€: job_id={job_id}")
                channel_result = {
                    'channel_id': channel_id,
                    'channel_name': result.channel_name,
                    'total_crawled': result.total_crawled,
                    'new_vehicles': result.new_vehicles,
                    'updated_vehicles': result.updated_vehicles,
                    'unchanged_vehicles': result.unchanged_vehicles,
                    'status': 'success',
                    'job_id': job_id
                }
                results.append(channel_result)
                completed_channels += 1
                progress = int((completed_channels / total_channels) * 100)
                current_task.update_state(
                    state='PROGRESS',
                    meta={
                        'current': completed_channels,
                        'total': total_channels,
                        'progress': progress,
                        'status': f'å·²å®Œæˆ {completed_channels}/{total_channels} ä¸ªæ¸ é“',
                        'results': results
                    }
                )
                app_logger.info(f"âœ… æ¸ é“ {channel_id} æ›´æ–°å®Œæˆ: æ–°å¢{result.new_vehicles}ä¸ª, æ›´æ–°{result.updated_vehicles}ä¸ª")
            except Exception as e:
                app_logger.error(f"âŒ æ¸ é“ {channel_id} æ›´æ–°å¤±è´¥: {e}")
                # æ›´æ–°ä»»åŠ¡è®°å½•ä¸ºå¤±è´¥çŠ¶æ€ - åŒæ­¥ç‰ˆæœ¬
                if job_id:
                    with get_sync_session() as db:
                        job = db.get(ProcessingJob, job_id)
                        if job:
                            job.status = "failed"
                            job.completed_at = datetime.utcnow()
                            job.result_summary = f"å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}"
                            db.commit()
                            app_logger.info(f"ğŸ“ æ›´æ–°å®šæ—¶ä»»åŠ¡è®°å½•ä¸ºå¤±è´¥çŠ¶æ€: job_id={job_id}")
                channel_result = {
                    'channel_id': channel_id,
                    'channel_name': f'æ¸ é“{channel_id}',
                    'error': str(e),
                    'status': 'failed',
                    'job_id': job_id
                }
                results.append(channel_result)
                completed_channels += 1
        # æ±‡æ€»ç»Ÿè®¡
        total_new = sum(r.get('new_vehicles', 0) for r in results if r.get('status') == 'success')
        total_updated = sum(r.get('updated_vehicles', 0) for r in results if r.get('status') == 'success')
        success_count = len([r for r in results if r.get('status') == 'success'])
        failed_count = len([r for r in results if r.get('status') == 'failed'])
        app_logger.info(f"ğŸ‰ å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å®Œæˆ: æˆåŠŸ{success_count}ä¸ªæ¸ é“, å¤±è´¥{failed_count}ä¸ªæ¸ é“, æ€»è®¡æ–°å¢{total_new}ä¸ªè½¦å‹, æ›´æ–°{total_updated}ä¸ªè½¦å‹")
        return {
            'status': 'completed',
            'total_channels': total_channels,
            'success_count': success_count,
            'failed_count': failed_count,
            'total_new_vehicles': total_new,
            'total_updated_vehicles': total_updated,
            'results': results,
            'message': f'å®šæ—¶è½¦å‹æ›´æ–°å®Œæˆ: æˆåŠŸ{success_count}/{total_channels}ä¸ªæ¸ é“'
        }
    except Exception as exc:
        app_logger.error(f"âŒ å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {exc}")
        current_task.update_state(
            state='FAILURE',
            meta={
                'error': str(exc),
                'message': f'å®šæ—¶è½¦å‹æ›´æ–°ä»»åŠ¡å¤±è´¥: {exc}'
            }
        )
        raise exc





@celery_app.task
def health_check():
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥ä»»åŠ¡ - åŒæ­¥ç‰ˆæœ¬
    """
    processing_job_id = None
    try:
        app_logger.info("ğŸ¥ æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        
        # åˆ›å»ºprocessing_jobè®°å½• - åŒæ­¥ç‰ˆæœ¬
        from app.core.database import get_sync_session
        from app.models.vehicle_update import ProcessingJob
        
        with get_sync_session() as db:
            processing_job = ProcessingJob(
                job_type="health_check",
                status="running",
                parameters={
                    "celery_task_id": health_check.request.id
                },
                pipeline_version="1.0.0",
                created_by_user_id_fk=None,
                started_at=datetime.utcnow()
            )
            db.add(processing_job)
            db.commit()
            db.refresh(processing_job)
            processing_job_id = processing_job.job_id
        
        app_logger.info(f"ğŸ“ åˆ›å»ºå¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•: job_id={processing_job_id}")
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        from app.core.database import sync_engine
        from sqlalchemy import text
        with sync_engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            db_status = "healthy" if result.fetchone() else "unhealthy"
        
        # æ£€æŸ¥Redisè¿æ¥
        from app.core.config import settings
        import redis
        try:
            r = redis.from_url(settings.REDIS_URL)
            r.ping()
            redis_status = "healthy"
        except:
            redis_status = "unhealthy"
        
        health_info = {
            'timestamp': datetime.now().isoformat(),
            'database': db_status,
            'redis': redis_status,
            'overall': "healthy" if db_status == "healthy" and redis_status == "healthy" else "unhealthy"
        }
        
        app_logger.info(f"âœ… å¥åº·æ£€æŸ¥å®Œæˆ: {health_info}")
        
        # æ›´æ–°processing_jobè®°å½•ä¸ºå®ŒæˆçŠ¶æ€ - åŒæ­¥ç‰ˆæœ¬
        with get_sync_session() as db:
            job = db.get(ProcessingJob, processing_job_id)
            if job:
                job.status = "completed"
                job.completed_at = datetime.utcnow()
                job.result_summary = f"å¥åº·æ£€æŸ¥å®Œæˆ: {health_info['overall']}"
                db.commit()
                app_logger.info(f"ğŸ“ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•ä¸ºå®ŒæˆçŠ¶æ€: job_id={processing_job_id}")
        
        return health_info
        
    except Exception as e:
        app_logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        
        # æ›´æ–°processing_jobè®°å½•ä¸ºå¤±è´¥çŠ¶æ€ - åŒæ­¥ç‰ˆæœ¬
        if processing_job_id:
            try:
                with get_sync_session() as db:
                    job = db.get(ProcessingJob, processing_job_id)
                    if job:
                        job.status = "failed"
                        job.completed_at = datetime.utcnow()
                        job.result_summary = f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}"
                        db.commit()
                        app_logger.info(f"ğŸ“ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•ä¸ºå¤±è´¥çŠ¶æ€: job_id={processing_job_id}")
            except Exception as update_error:
                app_logger.error(f"âŒ æ›´æ–°å¥åº·æ£€æŸ¥ä»»åŠ¡è®°å½•å¤±è´¥: {update_error}")
        
        return {
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'overall': 'unhealthy'
        } 