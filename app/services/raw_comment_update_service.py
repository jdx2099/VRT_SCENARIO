"""
åŸå§‹è¯„è®ºæ›´æ–°æœåŠ¡
å¤„ç†åŸå§‹è¯„è®ºæŸ¥è¯¢å’Œæ›´æ–°ç›¸å…³ä¸šåŠ¡é€»è¾‘
"""
from typing import List, Optional, Set
from sqlalchemy.orm import Session
from sqlalchemy import select, text
import httpx
import json
import time
import random
import asyncio
from datetime import datetime
from tqdm import tqdm

from app.core.database import AsyncSessionLocal
from app.core.logging import app_logger
from app.models.vehicle_update import VehicleChannelDetail, Channel
from app.models.raw_comment_update import RawComment, ProcessingStatus
from app.schemas.raw_comment_update import (
    RawCommentQueryRequest, RawCommentQueryResult, 
    VehicleChannelInfo, RawCommentCrawlRequest, RawCommentCrawlResult,
    NewCommentInfo
)


class RawCommentUpdateService:
    """
    åŸå§‹è¯„è®ºæ›´æ–°æœåŠ¡ç±»
    è´Ÿè´£å¤„ç†åŸå§‹è¯„è®ºç›¸å…³çš„ä¸šåŠ¡é€»è¾‘
    """
    
    def __init__(self):
        self.logger = app_logger

    async def crawl_new_comments_async(self, crawl_request: RawCommentCrawlRequest) -> "RawCommentCrawlTaskSchema":
        """
        å¯åŠ¨åŸå§‹è¯„è®ºå¼‚æ­¥çˆ¬å–ä»»åŠ¡
        
        Args:
            crawl_request: çˆ¬å–è¯·æ±‚å‚æ•°
            
        Returns:
            å¼‚æ­¥ä»»åŠ¡ä¿¡æ¯
        """
        try:
            # éªŒè¯è½¦å‹å­˜åœ¨æ€§
            vehicle_detail = await self.get_vehicle_by_channel_and_identifier(
                crawl_request.channel_id, crawl_request.identifier_on_channel
            )
            
            if not vehicle_detail:
                raise ValueError(f"æœªæ‰¾åˆ°åŒ¹é…çš„è½¦å‹: channel_id={crawl_request.channel_id}, identifier={crawl_request.identifier_on_channel}")
            
            # å¯¼å…¥Celeryä»»åŠ¡ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
            from app.tasks.crawler_tasks import crawl_raw_comments_async
            from app.schemas.raw_comment_update import RawCommentCrawlTaskSchema
            from datetime import datetime
            
            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
            task = crawl_raw_comments_async.delay(
                channel_id=crawl_request.channel_id,
                identifier_on_channel=crawl_request.identifier_on_channel,
                max_pages=crawl_request.max_pages
            )
            
            # åˆ›å»ºä»»åŠ¡è®°å½•
            task_schema = RawCommentCrawlTaskSchema(
                task_id=task.id,
                channel_id=crawl_request.channel_id,
                identifier_on_channel=crawl_request.identifier_on_channel,
                status="pending",
                message=f"å·²å¯åŠ¨ {vehicle_detail.name_on_channel} åŸå§‹è¯„è®ºçˆ¬å–ä»»åŠ¡",
                created_at=datetime.utcnow()
            )
            
            self.logger.info(f"ğŸš€ åŸå§‹è¯„è®ºçˆ¬å–ä»»åŠ¡å·²å¯åŠ¨: {task.id}")
            
            return task_schema
            
        except Exception as e:
            self.logger.error(f"âŒ å¯åŠ¨åŸå§‹è¯„è®ºçˆ¬å–ä»»åŠ¡å¤±è´¥: {e}")
            raise

    async def get_vehicle_raw_comment_ids(self, query_request: RawCommentQueryRequest) -> RawCommentQueryResult:
        """
        æ ¹æ®æ¸ é“IDå’Œè½¦å‹æ ‡è¯†è·å–è¯¥è½¦å‹ä¸‹çš„æ‰€æœ‰åŸå§‹è¯„è®ºID
        
        Args:
            query_request: æŸ¥è¯¢è¯·æ±‚å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœï¼ŒåŒ…å«è½¦å‹ä¿¡æ¯å’Œè¯„è®ºIDåˆ—è¡¨
            
        Raises:
            ValueError: å½“è½¦å‹ä¸å­˜åœ¨æ—¶
        """
        try:
            async with AsyncSessionLocal() as db:
                # ç¬¬ä¸€æ­¥ï¼šæ ¹æ®channel_idå’Œidentifier_on_channelæŸ¥è¯¢è½¦å‹æ¸ é“è¯¦æƒ…
                self.logger.info(f"ğŸ” æŸ¥è¯¢è½¦å‹: channel_id={query_request.channel_id}, identifier={query_request.identifier_on_channel}")
                
                vehicle_result = await db.execute(
                    select(VehicleChannelDetail).where(
                        VehicleChannelDetail.channel_id_fk == query_request.channel_id,
                        VehicleChannelDetail.identifier_on_channel == query_request.identifier_on_channel
                    )
                )
                vehicle_detail = vehicle_result.scalar_one_or_none()
                
                if not vehicle_detail:
                    raise ValueError(f"æœªæ‰¾åˆ°åŒ¹é…çš„è½¦å‹: channel_id={query_request.channel_id}, identifier={query_request.identifier_on_channel}")
                
                self.logger.info(f"âœ… æ‰¾åˆ°è½¦å‹: vehicle_channel_id={vehicle_detail.vehicle_channel_id}, name={vehicle_detail.name_on_channel}")
                
                # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨vehicle_channel_idæŸ¥è¯¢æ‰€æœ‰ç›¸å…³çš„åŸå§‹è¯„è®ºID
                comment_result = await db.execute(
                    select(RawComment.raw_comment_id).where(
                        RawComment.vehicle_channel_id_fk == vehicle_detail.vehicle_channel_id
                    ).order_by(RawComment.raw_comment_id)
                )
                raw_comment_ids = comment_result.scalars().all()
                
                self.logger.info(f"ğŸ“Š æ‰¾åˆ° {len(raw_comment_ids)} æ¡åŸå§‹è¯„è®º")
                
                # æ„å»ºè½¦å‹æ¸ é“ä¿¡æ¯
                vehicle_channel_info = VehicleChannelInfo(
                    vehicle_channel_id=vehicle_detail.vehicle_channel_id,
                    channel_id=vehicle_detail.channel_id_fk,
                    identifier_on_channel=vehicle_detail.identifier_on_channel,
                    name_on_channel=vehicle_detail.name_on_channel,
                    url_on_channel=vehicle_detail.url_on_channel,
                    temp_brand_name=vehicle_detail.temp_brand_name,
                    temp_series_name=vehicle_detail.temp_series_name,
                    temp_model_year=vehicle_detail.temp_model_year
                )
                
                # æ„å»ºæŸ¥è¯¢ç»“æœ
                result = RawCommentQueryResult(
                    vehicle_channel_info=vehicle_channel_info,
                    raw_comment_ids=list(raw_comment_ids),
                    total_comments=len(raw_comment_ids)
                )
                
                return result
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢è½¦å‹åŸå§‹è¯„è®ºIDå¤±è´¥: {e}")
            raise
    
    async def get_vehicle_by_channel_and_identifier(self, channel_id: int, identifier_on_channel: str) -> Optional[VehicleChannelDetail]:
        """
        æ ¹æ®æ¸ é“IDå’Œè½¦å‹æ ‡è¯†è·å–è½¦å‹è¯¦æƒ…
        
        Args:
            channel_id: æ¸ é“ID
            identifier_on_channel: è½¦å‹åœ¨æ¸ é“ä¸Šçš„æ ‡è¯†
            
        Returns:
            è½¦å‹æ¸ é“è¯¦æƒ…å¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            async with AsyncSessionLocal() as db:
                result = await db.execute(
                    select(VehicleChannelDetail).where(
                        VehicleChannelDetail.channel_id_fk == channel_id,
                        VehicleChannelDetail.identifier_on_channel == identifier_on_channel
                    )
                )
                return result.scalar_one_or_none()
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢è½¦å‹è¯¦æƒ…å¤±è´¥: {e}")
            raise
    
    async def count_raw_comments_by_vehicle_channel_id(self, vehicle_channel_id: int) -> int:
        """
        ç»Ÿè®¡æŒ‡å®šè½¦å‹æ¸ é“è¯¦æƒ…IDä¸‹çš„åŸå§‹è¯„è®ºæ•°é‡
        
        Args:
            vehicle_channel_id: è½¦å‹æ¸ é“è¯¦æƒ…ID
            
        Returns:
            è¯„è®ºæ•°é‡
        """
        try:
            async with AsyncSessionLocal() as db:
                from sqlalchemy import func
                result = await db.execute(
                    select(func.count(RawComment.raw_comment_id)).where(
                        RawComment.vehicle_channel_id_fk == vehicle_channel_id
                    )
                )
                return result.scalar()
        except Exception as e:
            self.logger.error(f"âŒ ç»Ÿè®¡åŸå§‹è¯„è®ºæ•°é‡å¤±è´¥: {e}")
            raise
    
    async def crawl_new_comments(self, crawl_request: RawCommentCrawlRequest) -> RawCommentCrawlResult:
        """
        çˆ¬å–æ–°çš„åŸå§‹è¯„è®º
        
        Args:
            crawl_request: çˆ¬å–è¯·æ±‚å‚æ•°
            
        Returns:
            çˆ¬å–ç»“æœï¼ŒåŒ…å«æ–°å¢è¯„è®ºä¿¡æ¯
        """
        start_time = time.time()
        
        try:
            async with AsyncSessionLocal() as db:
                # ç¬¬ä¸€æ­¥ï¼šè·å–è½¦å‹ä¿¡æ¯
                self.logger.info(f"ğŸ” å¼€å§‹çˆ¬å–è¯„è®º: channel_id={crawl_request.channel_id}, identifier={crawl_request.identifier_on_channel}")
                
                vehicle_detail = await self._get_vehicle_detail(db, crawl_request.channel_id, crawl_request.identifier_on_channel)
                if not vehicle_detail:
                    raise ValueError(f"æœªæ‰¾åˆ°åŒ¹é…çš„è½¦å‹: channel_id={crawl_request.channel_id}, identifier={crawl_request.identifier_on_channel}")
                
                # ç¬¬äºŒæ­¥ï¼šè·å–æ¸ é“é…ç½®
                channel_config = await self._get_channel_config(db, crawl_request.channel_id)
                if not channel_config:
                    raise ValueError(f"æœªæ‰¾åˆ°æ¸ é“é…ç½®: channel_id={crawl_request.channel_id}")
                
                # ç¬¬ä¸‰æ­¥ï¼šè·å–å·²æœ‰è¯„è®ºIDåˆ—è¡¨
                existing_comment_ids = await self._get_existing_comment_identifiers(db, vehicle_detail.vehicle_channel_id)
                self.logger.info(f"ğŸ“Š æ•°æ®åº“ä¸­å·²æœ‰ {len(existing_comment_ids)} æ¡è¯„è®º")
                
                # ç¬¬å››æ­¥ï¼šè·å–è¯„è®ºæ€»é¡µæ•°
                total_pages = await self._count_pages(channel_config, crawl_request.identifier_on_channel)
                self.logger.info(f"ğŸ“„ å…±å‘ç° {total_pages} é¡µè¯„è®º")
                
                # é™åˆ¶æœ€å¤§çˆ¬å–é¡µæ•°
                max_pages = min(total_pages, crawl_request.max_pages or total_pages)
                
                # ç¬¬äº”æ­¥ï¼šçˆ¬å–æ–°è¯„è®º
                new_comments = await self._collect_new_comments(
                    channel_config, 
                    crawl_request.identifier_on_channel,
                    max_pages,
                    existing_comment_ids,
                    vehicle_detail.vehicle_channel_id
                )
                
                # ç¬¬å…­æ­¥ï¼šçˆ¬å–è¯„è®ºè¯¦ç»†å†…å®¹
                if new_comments:
                    self.logger.info(f"ğŸ“ å¼€å§‹çˆ¬å– {len(new_comments)} æ¡è¯„è®ºçš„è¯¦ç»†å†…å®¹...")
                    await self._scrape_comments_contents(new_comments, channel_config)
                
                # ç¬¬ä¸ƒæ­¥ï¼šä¿å­˜æ–°è¯„è®ºåˆ°æ•°æ®åº“
                saved_count = await self._save_new_comments(db, new_comments, vehicle_detail.vehicle_channel_id)
                
                # æ„å»ºè½¦å‹æ¸ é“ä¿¡æ¯
                vehicle_channel_info = VehicleChannelInfo(
                    vehicle_channel_id=vehicle_detail.vehicle_channel_id,
                    channel_id=vehicle_detail.channel_id_fk,
                    identifier_on_channel=vehicle_detail.identifier_on_channel,
                    name_on_channel=vehicle_detail.name_on_channel,
                    url_on_channel=vehicle_detail.url_on_channel,
                    temp_brand_name=vehicle_detail.temp_brand_name,
                    temp_series_name=vehicle_detail.temp_series_name,
                    temp_model_year=vehicle_detail.temp_model_year
                )
                
                crawl_duration = time.time() - start_time
                
                result = RawCommentCrawlResult(
                    vehicle_channel_info=vehicle_channel_info,
                    total_pages_crawled=max_pages,
                    total_comments_found=len(new_comments),
                    new_comments_count=saved_count,
                    new_comments=[
                        NewCommentInfo(
                            identifier_on_channel=comment["identifier_on_channel"],
                            comment_content=comment["comment_content"],
                            posted_at_on_channel=comment["posted_at_on_channel"],
                            comment_source_url=comment.get("comment_source_url")
                        ) for comment in new_comments[:10]  # åªè¿”å›å‰10æ¡ç”¨äºå±•ç¤º
                    ],
                    crawl_duration=round(crawl_duration, 2)
                )
                
                self.logger.info(f"âœ… çˆ¬å–å®Œæˆ: å‘ç° {len(new_comments)} æ¡æ–°è¯„è®º, ä¿å­˜ {saved_count} æ¡, è€—æ—¶ {crawl_duration:.2f}ç§’")
                
                return result
                
        except Exception as e:
            self.logger.error(f"âŒ çˆ¬å–è¯„è®ºå¤±è´¥: {e}")
            raise
    
    async def _get_vehicle_detail(self, db, channel_id: int, identifier_on_channel: str) -> Optional[VehicleChannelDetail]:
        """è·å–è½¦å‹è¯¦æƒ…"""
        result = await db.execute(
            select(VehicleChannelDetail).where(
                VehicleChannelDetail.channel_id_fk == channel_id,
                VehicleChannelDetail.identifier_on_channel == identifier_on_channel
            )
        )
        return result.scalar_one_or_none()
    
    async def _get_channel_config(self, db, channel_id: int) -> Optional[dict]:
        """è·å–æ¸ é“é…ç½®"""
        result = await db.execute(
            select(Channel).where(Channel.channel_id == channel_id)
        )
        channel = result.scalar_one_or_none()
        if not channel or not channel.channel_base_url:
            return None
        
        try:
            # è§£æchannel_base_urlä¸­çš„JSONé…ç½®
            config = json.loads(channel.channel_base_url)
            return config
        except json.JSONDecodeError:
            self.logger.error(f"âŒ æ¸ é“é…ç½®JSONè§£æå¤±è´¥: channel_id={channel_id}")
            return None
    
    async def _get_existing_comment_identifiers(self, db, vehicle_channel_id: int) -> Set[str]:
        """è·å–å·²æœ‰è¯„è®ºæ ‡è¯†ç¬¦é›†åˆ"""
        result = await db.execute(
            select(RawComment.identifier_on_channel).where(
                RawComment.vehicle_channel_id_fk == vehicle_channel_id
            )
        )
        identifiers = result.scalars().all()
        return set(identifiers)
    
    async def _count_pages(self, channel_config: dict, identifier: str) -> int:
        """è®¡ç®—è¯„è®ºæ€»é¡µæ•°"""
        try:
            # ä»æ¸ é“é…ç½®ä¸­è·å–URLæ¨¡æ¿
            koubei_config = channel_config.get("koubei_series", {})
            url_template = koubei_config.get("url", "")
            
            if not url_template:
                raise ValueError("æ¸ é“é…ç½®ä¸­æœªæ‰¾åˆ°koubei_series.url")
            
            # æ„å»ºç¬¬ä¸€é¡µçš„URLæ¥è·å–æ€»é¡µæ•°
            # URLæ¨¡æ¿æ ¼å¼: {series_id} æ›¿æ¢ä¸ºç¬¬ä¸€ä¸ª{}ï¼Œ{page} æ›¿æ¢ä¸ºç¬¬äºŒä¸ª{}
            first_page_url = url_template.format(identifier, 1)
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(first_page_url)
                response.raise_for_status()
                
                data = response.json()
                page_count = data.get("result", {}).get("pagecount", 1)
                
                self.logger.info(f"ğŸ“„ ä»APIè·å–åˆ°æ€»é¡µæ•°: {page_count}")
                return int(page_count)
                
        except Exception as e:
            self.logger.error(f"âŒ è·å–é¡µæ•°å¤±è´¥: {e}")
            # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼1
            return 1
    
    async def _collect_new_comments(
        self, 
        channel_config: dict, 
        identifier: str, 
        max_pages: int,
        existing_identifiers: Set[str],
        vehicle_channel_id: int
    ) -> List[dict]:
        """æ”¶é›†æ–°è¯„è®º"""
        koubei_config = channel_config.get("koubei_series", {})
        url_template = koubei_config.get("url", "")
        
        if not url_template:
            raise ValueError("æ¸ é“é…ç½®ä¸­æœªæ‰¾åˆ°koubei_series.url")
        
        new_comments = []
        seen_identifiers = set()
        
        self.logger.info(f"ğŸ•·ï¸ å¼€å§‹çˆ¬å– {max_pages} é¡µè¯„è®º...")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            for page in tqdm(range(1, max_pages + 1), desc="çˆ¬å–è¯„è®ºé¡µé¢"):
                try:
                    # æ„å»ºå½“å‰é¡µé¢URL
                    # URLæ¨¡æ¿æ ¼å¼: {series_id} æ›¿æ¢ä¸ºç¬¬ä¸€ä¸ª{}ï¼Œ{page} æ›¿æ¢ä¸ºç¬¬äºŒä¸ª{}
                    page_url = url_template.format(identifier, page)
                    
                    response = await client.get(page_url)
                    response.raise_for_status()
                    
                    data = response.json()
                    comment_list = data.get("result", {}).get("list", [])
                    
                    for item in comment_list:
                        # è·å–è¯„è®ºIDï¼ˆå¯¹åº”è€ä»£ç ä¸­çš„Koubeiidï¼‰
                        koubei_id = str(item.get("Koubeiid", ""))
                        if not koubei_id:
                            continue
                        
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æˆ–é‡å¤
                        if koubei_id in existing_identifiers or koubei_id in seen_identifiers:
                            continue
                        
                        seen_identifiers.add(koubei_id)
                        
                        # è§£æè¯„è®ºåŸºæœ¬æ•°æ®ï¼ˆå†…å®¹å°†åœ¨åç»­æ­¥éª¤ä¸­çˆ¬å–ï¼‰
                        comment_data = {
                            "identifier_on_channel": koubei_id,
                            "comment_content": "",  # å†…å®¹å°†åœ¨è¯¦æƒ…çˆ¬å–æ­¥éª¤ä¸­å¡«å……
                            "posted_at_on_channel": self._parse_post_time(item.get("posttime", "")),
                            "comment_source_url": ""  # URLå°†åœ¨è¯¦æƒ…çˆ¬å–æ­¥éª¤ä¸­è®¾ç½®
                        }
                        
                        new_comments.append(comment_data)
                    
                    # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…åçˆ¬è™«
                    if page < max_pages:
                        await asyncio.sleep(random.uniform(1.0, 1.5))
                        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ç¬¬ {page} é¡µçˆ¬å–å¤±è´¥: {e}")
                    continue
        
        self.logger.info(f"ğŸ¯ æ”¶é›†åˆ° {len(new_comments)} æ¡æ–°è¯„è®º")
        return new_comments
    
    async def _scrape_comments_contents(self, new_comments: List[dict], channel_config: dict):
        """
        çˆ¬å–è¯„è®ºè¯¦ç»†å†…å®¹
        
        å‚æ•°ï¼š
            new_comments: æ–°è¯„è®ºåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« identifier_on_channel ç­‰å­—æ®µ
            channel_config: æ¸ é“é…ç½®ï¼ŒåŒ…å« koubei_detail.url æ¨¡æ¿
        """
        try:
            # è·å–è¯¦æƒ…APIé…ç½®
            koubei_detail_config = channel_config.get("koubei_detail", {})
            detail_url_template = koubei_detail_config.get("url", "")
            
            if not detail_url_template:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ° koubei_detail.url é…ç½®ï¼Œè·³è¿‡å†…å®¹çˆ¬å–")
                return
            
            self.logger.info(f"ğŸ”§ ä½¿ç”¨è¯¦æƒ…APIæ¨¡æ¿: {detail_url_template}")
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                for i, comment_data in enumerate(new_comments):
                    koubei_id = comment_data["identifier_on_channel"]
                    
                    try:
                        # çˆ¬å–å•ä¸ªè¯„è®ºè¯¦ç»†å†…å®¹
                        content = await self._scrape_single_comment_content(
                            client, koubei_id, detail_url_template
                        )
                        
                        # æ›´æ–°è¯„è®ºæ•°æ®
                        comment_data["comment_content"] = content
                        comment_data["comment_source_url"] = detail_url_template.format(koubei_id)
                        
                        self.logger.info(f"ğŸ“ [{i+1}/{len(new_comments)}] æˆåŠŸçˆ¬å–è¯„è®ºå†…å®¹ - KoubeiID: {koubei_id}")
                        
                        # æ·»åŠ å»¶è¿Ÿé¿å…åçˆ¬è™«
                        if i < len(new_comments) - 1:
                            await asyncio.sleep(random.uniform(1.0, 1.5))
                            
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ [{i+1}/{len(new_comments)}] çˆ¬å–å¤±è´¥ - KoubeiID: {koubei_id}, é”™è¯¯: {e}")
                        # è®¾ç½®é»˜è®¤å€¼ï¼Œé¿å…ä¿å­˜æ—¶å‡ºé”™
                        comment_data["comment_content"] = ""
                        comment_data["comment_source_url"] = detail_url_template.format(koubei_id)
            
            self.logger.info(f"âœ… è¯„è®ºå†…å®¹çˆ¬å–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ è¯„è®ºå†…å®¹çˆ¬å–å¤±è´¥: {e}")
            # ä¸ºæ‰€æœ‰è¯„è®ºè®¾ç½®é»˜è®¤å€¼
            for comment_data in new_comments:
                if "comment_content" not in comment_data:
                    comment_data["comment_content"] = ""
    
    async def _scrape_single_comment_content(
        self, 
        client: httpx.AsyncClient, 
        koubei_id: str, 
        url_template: str
    ) -> str:
        """
        çˆ¬å–å•ä¸ªè¯„è®ºçš„è¯¦ç»†å†…å®¹
        
        å‚æ•°ï¼š
            client: HTTPå®¢æˆ·ç«¯
            koubei_id: å£ç¢‘ID
            url_template: URLæ¨¡æ¿
            
        è¿”å›ï¼š
            è¯„è®ºå†…å®¹å­—ç¬¦ä¸²
        """
        try:
            # æ„å»ºè¯¦æƒ…URL
            detail_url = url_template.format(koubei_id)
            
            # å‘é€è¯·æ±‚
            response = await client.get(detail_url)
            response.raise_for_status()
            
            # è§£æJSONæ•°æ®
            data = response.json()
            
            # æå–è¯„è®ºå†…å®¹
            if data and "result" in data and "content" in data["result"]:
                content = data["result"]["content"]
                if content and content.strip():
                    return content.strip()
                else:
                    self.logger.debug(f"ğŸ“„ KoubeiID {koubei_id} å†…å®¹ä¸ºç©º")
                    return ""
            else:
                self.logger.warning(f"âš ï¸ KoubeiID {koubei_id} JSONæ ¼å¼å¼‚å¸¸: {data}")
                return ""
                
        except httpx.HTTPStatusError as e:
            self.logger.warning(f"âš ï¸ HTTPé”™è¯¯ - KoubeiID: {koubei_id}, çŠ¶æ€ç : {e.response.status_code}")
            return ""
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ - KoubeiID: {koubei_id}, é”™è¯¯: {e}")
            return ""
    
    def _parse_post_time(self, time_str: str) -> Optional[datetime]:
        """è§£æå‘å¸ƒæ—¶é—´"""
        if not time_str:
            return None
        
        try:
            # å°è¯•è§£æä¸åŒçš„æ—¶é—´æ ¼å¼
            time_formats = [
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d",
                "%Y/%m/%d %H:%M:%S",
                "%Y/%m/%d"
            ]
            
            for fmt in time_formats:
                try:
                    return datetime.strptime(time_str, fmt)
                except ValueError:
                    continue
            
            self.logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¶é—´æ ¼å¼: {time_str}")
            return None
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ—¶é—´è§£æå¼‚å¸¸: {e}")
            return None
    
    async def _save_new_comments(self, db, new_comments: List[dict], vehicle_channel_id: int) -> int:
        """ä¿å­˜æ–°è¯„è®ºåˆ°æ•°æ®åº“"""
        if not new_comments:
            return 0
        
        try:
            saved_count = 0
            
            for comment_data in new_comments:
                comment = RawComment(
                    vehicle_channel_id_fk=vehicle_channel_id,
                    identifier_on_channel=comment_data["identifier_on_channel"],
                    comment_content=comment_data["comment_content"],
                    posted_at_on_channel=comment_data["posted_at_on_channel"],
                    comment_source_url=comment_data["comment_source_url"],
                    # æ–°å¢ï¼šè®¾ç½®å¤„ç†çŠ¶æ€ä¸ºæ–°å»ºçŠ¶æ€
                    processing_status=ProcessingStatus.NEW
                )
                
                db.add(comment)
                saved_count += 1
            
            await db.commit()
            self.logger.info(f"ğŸ’¾ æˆåŠŸä¿å­˜ {saved_count} æ¡æ–°è¯„è®ºåˆ°æ•°æ®åº“")
            
            return saved_count
            
        except Exception as e:
            await db.rollback()
            self.logger.error(f"âŒ ä¿å­˜è¯„è®ºå¤±è´¥: {e}")
            raise


# å…¨å±€æœåŠ¡å®ä¾‹
raw_comment_update_service = RawCommentUpdateService() 